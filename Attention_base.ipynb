{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPv2XL4Z0u7OCiJCoVgV/p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VmPFzHCA6LrG","executionInfo":{"status":"ok","timestamp":1705505518774,"user_tz":-330,"elapsed":16,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"outputs":[],"source":["# Implementing self attention\n","import numpy as np\n","import math\n","import os"]},{"cell_type":"code","source":["ll=8# length of the input sequence\n","len_k=8# size of vectors\n","len_v=8# size of vectors\n","\n","q=np.random.randn(ll,len_k)#what is expected\n","k=np.random.randn(ll,len_k)#what is presented\n","v=np.random.randn(ll,len_v)#what is given\n","\n","mask=np.tril(np.ones((ll,ll)))\n","mask[mask==0]=-np.infty\n","mask[mask==1]=0"],"metadata":{"id":"18tRs6yVEkGI","executionInfo":{"status":"ok","timestamp":1705505518774,"user_tz":-330,"elapsed":13,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def scaled_dot_product_attention(q,k,v,mask=None):\n","    len_k=q.shape[1]\n","\n","    # Standard softmax\n","    def softmax(x):\n","        return np.exp(x).T/np.sum(np.exp(x),axis=-1).T\n","\n","    if mask is not None:\n","        attention=softmax(np.matmul(q,k.T)/math.sqrt(len_k)+mask)\n","\n","    # We are adding a denominator eases the convergence of the model\n","    # and keeps it better scaled preventing it from exploding\n","    attention=softmax(np.matmul(q,k.T)/math.sqrt(len_k))\n","\n","    # As one can see that, attention is trying to measure how closely\n","    # associated are q and k vectors. We later scale v as per that closness value\n","    ans=np.matmul(attention,v)\n","\n","    return ans, attention\n","\n","values, attention=scaled_dot_product_attention(q,k,v)"],"metadata":{"id":"7sVABAM7Je6w","executionInfo":{"status":"ok","timestamp":1705505518775,"user_tz":-330,"elapsed":13,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H1ZVPA8lPXGs","executionInfo":{"status":"ok","timestamp":1705505518775,"user_tz":-330,"elapsed":10,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3MnUYeXvPXSZ","executionInfo":{"status":"ok","timestamp":1705505518777,"user_tz":-330,"elapsed":12,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Implementing multi head attention\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"72DUtNNdOXfW","executionInfo":{"status":"ok","timestamp":1705505523538,"user_tz":-330,"elapsed":4771,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Number of words in a sequence\n","sentence_length = 12\n","batch_size = 1\n","\n","# Length of the vector representing a word\n","input_dim = 512\n","# Length of the vector representing a word after getting attention\n","d_model = 512\n","\n","sample_input = torch.randn( (batch_size, sentence_length, input_dim) )\n","\n","#3 to include qkv all 3 vectors\n","qkv_layer=nn.Linear(input_dim, 3*d_model)\n","\n","sample_input_qkv=qkv_layer(sample_input)"],"metadata":{"id":"Bi6-5YQtPrCn","executionInfo":{"status":"ok","timestamp":1705505523541,"user_tz":-330,"elapsed":19,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Picking 8 as the Attention is all u need had 8 self attention heads\n","num_heads=8\n","head_dim=d_model//num_heads\n","\n","sample_input_qkv=sample_input_qkv.reshape(batch_size,sentence_length ,num_heads,3*head_dim)"],"metadata":{"id":"NHDgOJ6VRUwu","executionInfo":{"status":"ok","timestamp":1705505523543,"user_tz":-330,"elapsed":19,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# We can get q, k and v seperately using\n","q, k, v = sample_input_qkv.chunk(3, dim=-1)"],"metadata":{"id":"fkaTt0KjSYWr","executionInfo":{"status":"ok","timestamp":1705505523543,"user_tz":-330,"elapsed":17,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#Hence building Multi head attention class by combining all the chunks under one\n","# hood\n","\n","# nn.Module is required for multiple nn functionalities\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, input_dim, d_model, num_heads):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n","        self.linear_layer = nn.Linear(d_model, d_model)\n","\n","    # Made some changes to work well for pytorch\n","    def __scaled_dot_product_attention(self,q,k,v,mask=None):\n","        len_k=q.shape[1]\n","\n","        if mask is not None:\n","            attention=F.softmax(torch.matmul(q,k.transpose(-1,-2))/math.sqrt(len_k)+mask,dim=-1)\n","        attention=F.softmax(torch.matmul(q,k.transpose(-1,-2))/math.sqrt(len_k),dim=-1)\n","        ans=torch.matmul(attention,v)\n","\n","        return ans, attention\n","\n","    def forward(self, x, mask=None):\n","        batch_size, sequence_length, input_dim = x.size()\n","        qkv = self.qkv_layer(x)\n","        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n","        qkv = qkv.permute(0, 2, 1, 3)\n","        q, k, v = qkv.chunk(3, dim=-1)\n","        values, attention = self.__scaled_dot_product_attention(q, k, v, mask)\n","        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n","        out = self.linear_layer(values)\n","        return out\n"],"metadata":{"id":"rs4_Mx7gTg9T","executionInfo":{"status":"ok","timestamp":1705505523545,"user_tz":-330,"elapsed":17,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["input_dim = 512\n","d_model = 512\n","num_heads = 8\n","\n","batch_size = 16\n","sequence_length = 32\n","x = torch.randn( (batch_size, sequence_length, input_dim) )\n","\n","model = MultiHeadAttention(input_dim, d_model, num_heads)\n","out = model.forward(x)"],"metadata":{"id":"mEKW5WoSWVQx","executionInfo":{"status":"ok","timestamp":1705505523545,"user_tz":-330,"elapsed":16,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rF4YQNNUWYKm","executionInfo":{"status":"ok","timestamp":1705505523547,"user_tz":-330,"elapsed":15,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5bwVZRKAYKvt","executionInfo":{"status":"ok","timestamp":1705505523547,"user_tz":-330,"elapsed":15,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Adding positional embeddings\n","\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"kvSXmIl6YK2j","executionInfo":{"status":"ok","timestamp":1705505524001,"user_tz":-330,"elapsed":468,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["max_sequence_length = 10\n","d_model = 6\n","\n","even_i = torch.arange(0, d_model, 2).float()\n","\n","# Denominator is kept high to spread embeddings as far as possible\n","even_denominator = torch.pow(10000, even_i/d_model)\n","\n","odd_i = torch.arange(1, d_model, 2).float()\n","odd_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n","\n","# As both of them will have the same denominator\n","denominator = even_denominator\n","\n","# Hence we define position as\n","position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)"],"metadata":{"id":"WPUZiMUPYLD5","executionInfo":{"status":"ok","timestamp":1705505524001,"user_tz":-330,"elapsed":34,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# We have broken these embeddings into sin and cosine to\n","# have periodicity. It also helps in linear transformations\n","\n","# Adding sin and cosine to get the final embeddings\n","even_pos_embds = torch.sin(position / denominator)\n","odd_pos_embds = torch.cos(position / denominator)\n","\n","# Just stacking even and odd position emeddings and reshaping it\n","final_pos_emb = torch.flatten(torch.stack([even_pos_embds, odd_pos_embds], dim=2), start_dim=1, end_dim=2)"],"metadata":{"id":"hD_98LWwZV-o","executionInfo":{"status":"ok","timestamp":1705505524001,"user_tz":-330,"elapsed":33,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, max_sequence_length):\n","        super().__init__()\n","        self.max_sequence_length = max_sequence_length\n","        self.d_model = d_model\n","\n","    def forward(self):\n","        even_i = torch.arange(0, self.d_model, 2).float()\n","        denominator = torch.pow(10000, even_i/self.d_model)\n","        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n","        even_pos_embds = torch.sin(position / denominator)\n","        odd_pos_embds = torch.cos(position / denominator)\n","        final_pos_emb = torch.flatten(torch.stack([even_pos_embds, odd_pos_embds], dim=2), start_dim=1, end_dim=2)\n","        return final_pos_emb"],"metadata":{"id":"zYhvKDKzd6TC","executionInfo":{"status":"ok","timestamp":1705505524002,"user_tz":-330,"elapsed":33,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["m = PositionalEncoding(d_model=6, max_sequence_length=10)\n","m.forward()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ii40RwfYfMXX","executionInfo":{"status":"ok","timestamp":1705505524002,"user_tz":-330,"elapsed":32,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}},"outputId":"67c2ac08-ae67-4795-e623-0f264b040c0a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n","        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n","        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n","        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n","        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n","        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n","        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n","        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n","        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n","        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"lWmEsi3dfODW","executionInfo":{"status":"ok","timestamp":1705505524006,"user_tz":-330,"elapsed":35,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Uof4ghL3hHB7","executionInfo":{"status":"ok","timestamp":1705505524007,"user_tz":-330,"elapsed":35,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Implementing layer normalization\n","\n","# Its quite straight forward, just like standard\n","# layer normalization in NN, implemented it for the sake of completeness\n","import torch\n","from torch import nn\n","\n","class LayerNormalization(nn.Module):\n","    def __init__(self, parameters_shape, eps=1e-5):\n","        super().__init__()\n","        self.parameters_shape=parameters_shape\n","        self.eps=eps #eps task is not to make denominator zero.\n","\n","        # Standard gamma and beta, please read on layer normalization\n","        # for better understading\n","        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n","        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n","\n","    def forward(self, inputs):\n","        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n","        mean = inputs.mean(dim=dims, keepdim=True)\n","        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n","        std = (var + self.eps).sqrt()\n","        y = (inputs - mean) / std\n","        out = self.gamma * y  + self.beta\n","        return out"],"metadata":{"id":"WSpDAtRQhHIL","executionInfo":{"status":"ok","timestamp":1705505816742,"user_tz":-330,"elapsed":19,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["batch_size = 3\n","sentence_length = 5\n","embedding_dim = 8\n","inp= torch.randn(sentence_length, batch_size, embedding_dim)\n","\n","ln = LayerNormalization(inp.size()[-1:])\n","ln.forward(inp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1f2n-tTiC9v","executionInfo":{"status":"ok","timestamp":1705505816744,"user_tz":-330,"elapsed":19,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}},"outputId":"5d0416c8-72ab-46cf-e676-8920ad53c590"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.2237,  1.0983,  0.2260,  1.5452, -1.9365, -0.3385, -0.1797,\n","          -0.6386],\n","         [-1.8442,  0.3109,  0.0218,  1.8186,  0.7396, -0.4677, -0.6508,\n","           0.0719],\n","         [-0.0671,  0.6382,  0.5755, -1.9717, -0.3274,  1.7403, -0.1199,\n","          -0.4680]],\n","\n","        [[-0.2946,  0.5916, -1.3892,  1.6275,  0.4714, -1.5742,  0.5317,\n","           0.0359],\n","         [ 1.5515, -0.0539, -1.6339, -1.4856,  0.4523,  0.2235,  0.5474,\n","           0.3987],\n","         [-1.6624,  0.5187,  0.9759,  0.6120, -0.2483,  1.4459, -1.0857,\n","          -0.5562]],\n","\n","        [[ 0.1705, -1.3284,  0.5025, -0.0973,  1.2032, -0.2297,  1.3761,\n","          -1.5968],\n","         [ 0.2413, -0.2644, -0.1772,  0.2880, -2.0577, -0.2358,  1.8222,\n","           0.3836],\n","         [-0.1622,  0.1519,  0.3245, -0.9380,  2.2040,  0.2185, -0.4294,\n","          -1.3694]],\n","\n","        [[ 0.5888, -0.1128, -0.3977, -2.4148,  0.9547,  0.3274,  0.3317,\n","           0.7228],\n","         [ 1.0433,  0.2276, -2.0210, -0.6999, -0.5630,  0.1693,  1.2682,\n","           0.5756],\n","         [ 1.7171,  0.8703,  0.2761,  0.4384, -0.8901, -0.1768, -0.5239,\n","          -1.7111]],\n","\n","        [[-1.1200, -0.2067, -0.4722,  0.3965, -0.0635, -1.3667,  1.8848,\n","           0.9477],\n","         [ 1.7799, -1.8020, -0.9786,  0.5229,  0.4568,  0.2519, -0.2807,\n","           0.0499],\n","         [-0.3160, -0.3331, -0.0382, -0.7882, -0.1164, -0.2030,  2.5559,\n","          -0.7610]]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"74BEgCboiLM4","executionInfo":{"status":"ok","timestamp":1705505816746,"user_tz":-330,"elapsed":12,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L4rIRBtZXkUB","executionInfo":{"status":"ok","timestamp":1705505816747,"user_tz":-330,"elapsed":12,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Let us create the encoder\n","\n","# To create an encoder we will need one more component\n","# that is a normal feed forward NN\n","class FeedForwardLayer(nn.Module):\n","# Positionwise\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super().__init__()\n","        # PositionwiseFeedForward, self\n","        self.linear1 = nn.Linear(d_model, hidden)\n","        self.linear2 = nn.Linear(hidden, d_model)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x"],"metadata":{"id":"DPnuikYNY_qg","executionInfo":{"status":"ok","timestamp":1705505816749,"user_tz":-330,"elapsed":14,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n","        super(EncoderLayer, self).__init__()\n","        self.attention = MultiHeadAttention(input_dim=d_model,d_model=d_model, num_heads=num_heads)\n","        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","        self.ffn = FeedForwardLayer(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        # PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        residual_x = x\n","        x = self.attention(x, mask=None)\n","        x = self.dropout1(x)\n","        x = self.norm1(x + residual_x)\n","        residual_x = x\n","        x = self.ffn(x)\n","        x = self.dropout2(x)\n","        x = self.norm2(x + residual_x)\n","        return x\n","\n","class Encoder(nn.Module):\n","    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n","        super().__init__()\n","        self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n","                                     for _ in range(num_layers)])\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x\n"],"metadata":{"id":"ZUHP3GuZXkW5","executionInfo":{"status":"ok","timestamp":1705505817357,"user_tz":-330,"elapsed":5,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["d_model = 512\n","num_heads = 8\n","drop_prob = 0.1\n","batch_size = 30\n","max_sequence_length = 200\n","ffn_hidden = 2048\n","num_layers = 5\n","\n","encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n","x = torch.randn( (batch_size, max_sequence_length, d_model) ) # includes positional encoding\n","out = encoder(x)\n","out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tx6x0lQ2XqXC","executionInfo":{"status":"ok","timestamp":1705505867682,"user_tz":-330,"elapsed":11624,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}},"outputId":"f95671ad-9645-4f06-87df-a39eb56298f8"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.1632,  1.7173,  0.3889,  ...,  0.2849,  0.7005,  2.4774],\n","         [-0.6468,  0.9080, -0.8771,  ..., -0.2510,  0.0443, -0.0343],\n","         [-0.4627, -1.7106,  2.6224,  ..., -0.8283,  1.4733,  1.3020],\n","         ...,\n","         [-0.7132, -0.7054,  0.9903,  ..., -1.6433,  0.3756,  0.2808],\n","         [-2.1918,  0.0538,  0.4344,  ..., -1.0681, -0.6622,  0.3531],\n","         [-0.4224, -0.2407,  0.9645,  ..., -0.6999, -1.0355,  0.1379]],\n","\n","        [[-0.7046, -3.2670,  0.5777,  ...,  0.9631, -1.0930,  0.5923],\n","         [ 0.0895, -0.7336, -0.0172,  ...,  0.0103,  0.6214,  2.1696],\n","         [-2.2934,  0.7928,  0.7273,  ..., -1.1329, -2.4574, -0.9656],\n","         ...,\n","         [ 1.1689, -0.0733, -0.3280,  ..., -0.0928,  0.0429,  1.2562],\n","         [-0.5154, -0.4037,  1.6376,  ..., -1.9652, -1.0129, -0.5088],\n","         [ 0.5483,  0.8973,  0.3489,  ..., -0.6195, -2.2616,  0.8052]],\n","\n","        [[ 0.7434, -2.6322, -0.1220,  ..., -1.4290, -0.2546,  2.6429],\n","         [-2.0935,  1.5937, -0.4408,  ...,  0.3552, -0.5905,  2.5412],\n","         [ 0.2812,  0.6725, -1.4480,  ..., -0.5175, -1.0650,  1.9651],\n","         ...,\n","         [ 1.3573, -1.2523,  0.1263,  ..., -0.1571,  1.1160,  2.1181],\n","         [-0.6241, -0.3099, -1.6647,  ...,  0.4401, -0.6124, -1.5803],\n","         [-1.3290, -2.1323,  0.2039,  ..., -0.3473, -1.0709,  1.5518]],\n","\n","        ...,\n","\n","        [[-0.6847, -0.5505, -0.4598,  ..., -1.3379, -0.3806,  0.2658],\n","         [ 0.2993,  0.0384,  0.8638,  ..., -0.1282,  0.6284,  0.6688],\n","         [ 0.4386,  0.3114, -0.1996,  ..., -0.2454,  0.4282,  1.5637],\n","         ...,\n","         [-0.5784,  1.1417, -0.6343,  ...,  0.0067, -0.1346, -1.8070],\n","         [-0.7224,  0.2687,  0.8451,  ..., -0.1396, -0.2742,  1.2194],\n","         [ 0.2800,  1.5792, -0.0217,  ...,  0.8794, -2.0132,  0.7287]],\n","\n","        [[-1.5806, -1.2147, -1.3945,  ...,  2.3861,  1.7279, -0.9158],\n","         [ 0.0084,  0.2479,  0.3484,  ...,  0.5612,  0.1988, -0.1653],\n","         [ 0.3137, -0.1444, -2.2836,  ...,  1.5971, -0.6544,  1.5577],\n","         ...,\n","         [-0.8679, -0.8445, -0.3085,  ..., -1.0365,  0.0093,  0.8968],\n","         [ 1.6719, -0.2894, -0.5459,  ...,  0.2506, -0.6204,  1.5504],\n","         [-0.2942, -1.3892, -0.9575,  ..., -1.7618, -0.1825,  0.5456]],\n","\n","        [[-0.2541,  0.2014, -0.0379,  ..., -0.4808,  1.1581,  0.0493],\n","         [-0.3584,  1.2848,  0.2099,  ..., -0.0242,  0.4492, -0.7305],\n","         [-1.5862, -0.8244, -2.5137,  ..., -0.9112,  0.0069,  0.8830],\n","         ...,\n","         [-0.8535, -2.4481, -0.8964,  ...,  0.6387,  1.0453, -0.4356],\n","         [ 0.8326,  0.6619, -2.1369,  ..., -0.0602,  0.9746,  0.3000],\n","         [-1.6546,  0.5037,  0.1307,  ...,  0.9909,  0.9896, -0.5097]]],\n","       grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"zLKarMshXqqx","executionInfo":{"status":"aborted","timestamp":1705505525268,"user_tz":-330,"elapsed":10,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AbdOf4u2DN0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AYBaFosGEoeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Coding decoder\n","\n","# We need a multi head cross attention module as in the decoder, we are\n","# connecting k and v from encoder and q from the decoder\n","# Other wise its mostly like self attention.\n","class MultiHeadCrossAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","\n","        # This is taken from the encoder\n","        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n","        # This is taken from the decoder\n","        self.q_layer = nn.Linear(d_model , d_model)\n","        self.linear_layer = nn.Linear(d_model, d_model)\n","\n","    # Made some changes to work well for pytorch\n","    def __scaled_dot_product_attention(self,q,k,v,mask=None):\n","        len_k=q.shape[1]\n","\n","        if mask is not None:\n","            attention=F.softmax(torch.matmul(q,k.transpose(-1,-2))/math.sqrt(len_k)+mask,dim=-1)\n","        attention=F.softmax(torch.matmul(q,k.transpose(-1,-2))/math.sqrt(len_k),dim=-1)\n","        ans=torch.matmul(attention,v)\n","\n","        return ans, attention\n","\n","\n","    def forward(self, x, y, mask=None):\n","        batch_size, sequence_length, d_model = x.size()\n","        kv = self.kv_layer(x)\n","        q = self.q_layer(y)\n","\n","        # Some matrix multiplications\n","        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n","        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n","        kv = kv.permute(0, 2, 1, 3)\n","        q = q.permute(0, 2, 1, 3)\n","        k, v = kv.chunk(2, dim=-1)\n","\n","        values, attention = self.__scaled_dot_product_attention(q, k, v, mask)\n","        values = values.reshape(batch_size, sequence_length, d_model)\n","        out = self.linear_layer(values)\n","        return out"],"metadata":{"id":"DPyJSM0xDN_r","executionInfo":{"status":"ok","timestamp":1705507997150,"user_tz":-330,"elapsed":4,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Same as positional encoding but with more layer and dropouts\n","class PositionwiseFeedForward(nn.Module):\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.linear1 = nn.Linear(d_model, hidden)\n","        self.linear2 = nn.Linear(hidden, d_model)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x\n","\n","\n","class DecoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n","        super(DecoderLayer, self).__init__()\n","        self.self_attention = MultiHeadAttention(input_dim=d_model,d_model=d_model, num_heads=num_heads)\n","        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n","        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm3 = LayerNormalization(parameters_shape=[d_model])\n","        self.dropout3 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x, y, decoder_mask):\n","        _y = y\n","        y = self.self_attention(y, mask=decoder_mask)\n","        y = self.dropout1(y)\n","        y = self.norm1(y + _y)\n","\n","        _y = y\n","        y = self.encoder_decoder_attention(x, y, mask=None)\n","        y = self.dropout2(y)\n","        y = self.norm2(y + _y)\n","\n","        _y = y\n","        y = self.ffn(y)\n","        y = self.dropout3(y)\n","        y = self.norm3(y + _y)\n","        return y\n"],"metadata":{"id":"-_MVJ47YFlZm","executionInfo":{"status":"ok","timestamp":1705507997633,"user_tz":-330,"elapsed":8,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["class SequentialDecoder(nn.Sequential):\n","    # Yes, simple forward pass\n","    def forward(self, *inputs):\n","        x, y, mask = inputs\n","        for module in self._modules.values():\n","            y = module(x, y, mask)\n","        return y\n","\n","class Decoder(nn.Module):\n","    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers=1):\n","        super().__init__()\n","        # Combining multiple decoder layers\n","        # * means sending all parametric output to Sequential Decoder\n","        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n","                                          for _ in range(num_layers)])\n","\n","    def forward(self, x, y, mask):\n","        y = self.layers(x, y, mask)\n","        return y"],"metadata":{"id":"QRJk6ffIGUlG","executionInfo":{"status":"ok","timestamp":1705507997635,"user_tz":-330,"elapsed":9,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["d_model = 512\n","num_heads = 8\n","drop_prob = 0.1\n","batch_size = 30\n","max_sequence_length = 200\n","ffn_hidden = 2048\n","num_layers = 5\n","\n","x = torch.randn( (batch_size, max_sequence_length, d_model) ) # English sentence positional encoded\n","y = torch.randn( (batch_size, max_sequence_length, d_model) ) # Translated sentence positional encoded\n","mask = torch.full([max_sequence_length, max_sequence_length] , float('-inf'))\n","mask = torch.triu(mask, diagonal=1)\n","decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n","out = decoder(x, y, mask)\n","out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojXSSQJhGlht","executionInfo":{"status":"ok","timestamp":1705508038429,"user_tz":-330,"elapsed":11923,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}},"outputId":"0c5dcc06-1ef7-45ef-ade6-82472cc22538"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.4949, -0.8757,  0.8508,  ..., -0.9956, -0.9012, -0.0676],\n","         [ 1.3021, -0.6950,  0.6334,  ...,  0.4350,  0.1510,  0.4122],\n","         [ 0.4655, -1.3297, -0.8419,  ..., -0.2157, -0.9272, -2.6891],\n","         ...,\n","         [ 0.8866,  0.2122, -1.1576,  ..., -1.3499, -0.8153, -0.8631],\n","         [-0.0675, -1.9018, -2.2976,  ...,  1.6301, -0.2300, -1.9203],\n","         [ 0.2834, -0.8018,  1.4648,  ...,  0.5247,  0.9794,  0.1147]],\n","\n","        [[-1.8060,  0.1756,  0.8302,  ..., -0.3361, -0.1578, -0.3368],\n","         [ 0.0628,  0.8252, -0.6606,  ...,  1.5227, -1.3413,  0.5388],\n","         [-0.5399, -0.5199,  0.1767,  ..., -1.7849,  1.1637,  0.7453],\n","         ...,\n","         [-1.0900, -0.1581, -0.0456,  ...,  0.1248, -0.3921,  1.2611],\n","         [ 0.6246,  0.2772,  1.0177,  ...,  0.4094,  0.5543, -0.2030],\n","         [-1.2364,  0.7276,  1.3087,  ..., -0.7991,  2.2529,  0.3428]],\n","\n","        [[-0.8552, -0.0092,  0.8440,  ..., -0.5720, -0.9373,  1.2939],\n","         [ 0.2559, -1.0715,  0.7552,  ...,  0.3038,  0.1166, -0.3864],\n","         [ 1.5045, -1.1238,  1.6053,  ...,  0.3731,  0.0924,  0.4863],\n","         ...,\n","         [-1.7869, -0.6889,  1.0366,  ...,  0.4573, -2.0949,  0.7395],\n","         [-0.4058, -0.4147, -0.5131,  ..., -0.2823, -0.6160, -0.4466],\n","         [ 0.2959,  0.3909,  0.2304,  ..., -1.0761,  0.6245, -0.3607]],\n","\n","        ...,\n","\n","        [[ 0.3604, -1.1112,  1.1565,  ...,  0.6099,  0.6681, -0.3813],\n","         [-0.8842, -0.5348,  0.2323,  ..., -1.7826, -0.1991, -0.3306],\n","         [ 0.1095, -0.7924,  0.3535,  ...,  0.4847,  2.3962, -0.3036],\n","         ...,\n","         [ 0.1329, -0.7317, -0.8369,  ...,  0.4822, -0.5308,  0.9211],\n","         [-0.1628,  2.4330,  0.8712,  ...,  1.7112,  0.8659, -0.1895],\n","         [-1.0356, -0.0291, -0.2762,  ..., -0.8855,  0.8507,  0.1115]],\n","\n","        [[ 1.6184,  1.4724,  1.2255,  ...,  0.8833, -0.2717, -1.8200],\n","         [-0.6712, -0.5333,  0.9002,  ...,  0.1800, -0.9827,  0.2985],\n","         [-0.2704, -0.7096,  0.7914,  ...,  1.7109,  0.0540, -0.1926],\n","         ...,\n","         [-0.1974, -0.6819,  0.5232,  ..., -0.6387, -1.2971, -0.5514],\n","         [ 0.2137, -0.8612, -0.1637,  ...,  1.2970,  0.2887,  0.5317],\n","         [-0.6612,  0.3618, -0.2230,  ...,  1.9150, -0.4925, -1.0181]],\n","\n","        [[-0.3445, -0.5937,  1.3989,  ...,  1.3149, -0.1135, -0.3439],\n","         [-0.0786, -0.3882,  0.7502,  ..., -0.8609, -0.5778, -0.7035],\n","         [-0.5314, -1.3577,  1.6408,  ..., -0.7809, -0.4745, -0.1983],\n","         ...,\n","         [ 1.2172, -0.2285,  0.7994,  ...,  1.0638, -0.8499, -0.1765],\n","         [-1.2484, -0.2100,  1.8620,  ...,  0.5983, -1.5294, -1.9920],\n","         [ 0.5191,  0.8404, -0.0491,  ...,  1.0416, -0.5413,  1.4593]]],\n","       grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":[],"metadata":{"id":"1bhY-IGmGnEA","executionInfo":{"status":"aborted","timestamp":1705506431130,"user_tz":-330,"elapsed":12,"user":{"displayName":"Apurva Bhatt","userId":"07525810954861639294"}}},"execution_count":null,"outputs":[]}]}